{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "     \n",
    "                        CHEATSHEET BERLIN IRONHACK 2021\n",
    "                                CHRISTOPH AMESEDER\n",
    "        \n",
    "                                Stand 13.01.2021 \n",
    "                (Python coding commands after 3 days, please report errors)\n",
    "\n",
    "######################################################################################\n",
    "                                 IMPORT AND READ\n",
    "#####################################################################################\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#importing data using realtive path\n",
    "#../file_name.csv (going one data folder up)\n",
    "# data_folder/file_name.csv (going into one folder to data file)\n",
    "data = pd.read_csv('files_for_Lab/csv_files/file_name.csv')\n",
    "#dat2= pd.read_csv('files_for_activities/csv_files/merged_clean_ver2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################\n",
    "                                 DATA EXPLORATION\n",
    "#####################################################################################\n",
    "\n",
    "\n",
    "#rows and columns returns (rows, columns)\n",
    "data.shape\n",
    "\n",
    "#returns the first x number of rows when head(num). Without a number it returns 5\n",
    "data.head()\n",
    "\n",
    "#returns the last x number of rows when tail(num). Without a number it returns 5\n",
    "data.tail()\n",
    "\n",
    "#returns an object with all of the column headers \n",
    "data.columns\n",
    "\n",
    "#basic information on all columns \n",
    "data.info()\n",
    "\n",
    "#gives basic statistics on numeric columns\n",
    "data.describe()\n",
    "\n",
    "#shows what type the data was read in as (float, int, string, bool, etc.)\n",
    "data.dtypes\n",
    "data._get_numeric_data()\n",
    "data._get_numeric_data()\n",
    "\n",
    "#shows which values are null\n",
    "data.isnull()\n",
    "\n",
    "#shows which columns have null values\n",
    "data.isnull().any()\n",
    "\n",
    "#shows for each column the percentage of null values (data shape[0] is the same as len(data))\n",
    "data.isnull().sum() / data.shape[0]\n",
    "\n",
    "#plot histograms for all numeric columns \n",
    "data.hist() \n",
    "\n",
    "# FOR CATEGORICAL VARIABLES\n",
    "\n",
    "#shows unique values that appear in the column \n",
    "data.type = data['type']\n",
    "data.type.unique()\n",
    "\n",
    "#shows the counts for those unique values \n",
    "data.type.value_counts()\n",
    "\n",
    "#shows the percentage of values from \n",
    "data.type.value_counts()/ data.type.notnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./called_notebook.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################\n",
    "                                 DATA CLEANING AND MANIPULATION\n",
    "#####################################################################################\n",
    "\n",
    "# Creating a copy before we start with data cleaning process\n",
    "temp = data.copy()\n",
    "\n",
    "# rename columns \n",
    "data.rename(index=str columns={'col_oldname':'col_newname'})\n",
    "\n",
    "# view all rows for one column\n",
    "data.col_name \n",
    "data['col_name']\n",
    "\n",
    "# multiple columns by name\n",
    "data[['col1','col2']]\n",
    "data.loc[:['col1','col2']]\n",
    "\n",
    "#columns by index \n",
    "data.iloc[:,[0:2]]\n",
    "\n",
    "# drop columns \n",
    "data.drop('colname', axis =1) #add inplace = True to do save over current dataframe\n",
    "\n",
    "#drop multiple \n",
    "data.drop(['col1','col2'], axis =1)\n",
    "\n",
    "#add column \n",
    "data['age'] = 2019 - data['year']\n",
    "\n",
    "#iterate over header (columns) and do a operation (here.lower)\n",
    "cols = []\n",
    "for i in range(len(data.columns)):\n",
    "    cols.append(data.columns[i].lower())\n",
    "\n",
    "#renaming columns using dictionary\n",
    "data = data.rename(columns={ 'controln':'id','hv1':'median_home_val', 'ic1':'median_household_income'})\n",
    "\n",
    "#rearanging columns either use list or directly column names as in this example\n",
    "data = data[['id', 'state', 'gender', 'median_home_val']]\n",
    "\n",
    "#attach two dataframes to each other\n",
    "data = pd.concat([data,data2], axis=0) #axis=0 meaning rows, axis=1 columns get attached next to e.o.\n",
    "\n",
    "# merge  == JOIN in SQL, on = column or index to merge on, method: which keys are used\n",
    "pd.merge(data1, data2, how = 'inner' , on = 'col1')\n",
    "\n",
    "#filter for multiple columns (all below do the same thing ) \n",
    "data[['url','city','price']]\n",
    "data.loc[:,['url','city','price']]\n",
    "data.iloc[:,0:3]\n",
    "\n",
    "#filter by rows and columns \n",
    "data.loc[0:100,['url','city','price']]\n",
    "data.iloc[0:100,0:3]\n",
    "\n",
    "#filter by column list \n",
    "data[data.columns]\n",
    "\n",
    "# filtering and subsetting -- using conditions with dataframes & boolean indexing\n",
    "data[data['gender']=='M']\n",
    "data[data['gender'].isin(['M', 'F'])]\n",
    "data[(data['gender']=='M') | (data['gender']=='F')]\n",
    "data[data['target_d']>100]\n",
    "data[(data['target_d']<100) & (data['gender']=='F')]\n",
    "\n",
    "#lambda function \n",
    "data.apply(lambda x: x.colname**2, axis =1)\n",
    "\n",
    "#lambda\n",
    "square = lambda x: x*x\n",
    "\n",
    "#tenary operator, conditional expressions using lambdas \n",
    "data['expensive'] = data['price'].apply(lambda x: 'expensive' if x > 10000 else 'cheap')\n",
    "data['newandcheap'] = data.apply(lambda x: 'yes' if x['price'] < 10000 and x['age'] < 5 else 'no', axis = 1)\n",
    "data['newandcheap2'] = data[['price','age']].apply(lambda x: 'yes' if x[0] < 10000 and x[1] < 5 else 'no', axis = 1)\n",
    "\n",
    "#converting argument to numeric  error='coerce' replaces the values that are not floats to NaNs\n",
    "data['median_home_val'] =  pd.to_numeric(data['median_home_val'], errors='coerce')\n",
    "data['ic5'] =  pd.to_numeric(data['ic5'], errors='coerce')\n",
    "\n",
    "#converting column to string\n",
    "df['id'].astype(str)\n",
    "\n",
    "#map function\n",
    "data['gender'] = list(map(lambda x: x.upper(), data['gender'])) \n",
    "\n",
    "# Creating buckets / groups of data \n",
    "ic2_labels = ['Low', 'Moderate', 'High', 'Very High']\n",
    "data['ic2_'] = pd.cut(data['ic2'],4, labels=ic2_labels)\n",
    "\n",
    "# dealing with date-time-format\n",
    "file['date_time'] = pd.to_datetime(file['date_time'], errors='coerce')\n",
    "file['date_time'][0].day\n",
    "file['date_time'][0].month\n",
    "file['date_time'][0].year\n",
    "file['date_time'][0].isoweekday()  # Returns 1 for Monday and so on\n",
    "file['date_time'][0].time()\n",
    "file['date_time'][0].strftime(format='%d-%M-%Y')\n",
    "file['date_time'][0].strftime(format=\"%A %d. %B %Y\")\n",
    "\n",
    "#string manipulation\n",
    "string = \" I am learning  data  analysis at Ironhack  . It is  super easy \"\n",
    "string.lower()\n",
    "string.upper()\n",
    "'34'.isdigit() # does not work with decimal numbers\n",
    "string.lstrip()\n",
    "string.rstrip()\n",
    "string.split()\n",
    "string.split('.')\n",
    "\n",
    "# Removing duplicates\n",
    "data = data.drop_duplicates()\n",
    "\n",
    "# write to csv \n",
    "data.to_csv('data_out.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################\n",
    "                                 GRAPHING\n",
    "#####################################################################################\n",
    "\n",
    "#histogram of year \n",
    "# data.year.hist() == data.year.plot(kind='hist')\n",
    "data.year.hist()\n",
    "data.year.hist(bins=100)\n",
    "#bar chart of types \n",
    "data.type.value_counts().plot(kind='bar')\n",
    "\n",
    "#Scatterplott\n",
    "plt.scatter(x=data['ic2'], y=data['ic3'])\n",
    "plt.show()\n",
    "\n",
    "#Histogram\n",
    "data['median_home_val'].hist()\n",
    "plt.show()\n",
    "\n",
    "sns.distplot(data['median_home_val'], bins=20)\n",
    "plt.show()\n",
    "\n",
    "#Boxplot\n",
    "data[['median_home_val']].boxplot()\n",
    "plt.show()\n",
    "\n",
    "sns.boxplot(y=\"median_home_val\", data=data)\n",
    "plt.show()\n",
    "\n",
    "sns.boxplot(x = 'gender',y='median_home_val', data=data)\n",
    "plt.show()\n",
    "\n",
    "#Barplot\n",
    "sns.barplot(x=\"gender\", y=\"median_home_val\", data=data)\n",
    "plt.show()\n",
    "\n",
    "sns.barplot(x=\"gender\", y=\"median_home_val\", hue= 'ic2_', data=data)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
